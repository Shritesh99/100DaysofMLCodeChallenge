# 100 Days of ML Code Challenge
## 100 Days of Machine Learning Coding as proposed by [Siraj Raval](https://github.com/llSourcell)

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/ML_cheatsheet-01.png">
</p>

## Machine Learning
### Day 0 :- Gather all the tools for Data Science.
**Today's Work** :- Today I have installed all the tools and packages required for this challenge.
### Day 1 :- Data Preprocessing
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/16089b74f029151e98ba90ed54f92c52ed8d9643).
**Today's Work** :- I have completed the most crucial Data Preprocessing step on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Data-Preprocessing/Data.csv).

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%201.jpg">
</p>

### Day 2 :- Simple Linear Regression
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/e2894b2ce2d37c4dbd3aa64e0563a48c29936cfb).

**Today's work**:- I have applied Simple Linear Regression on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Simple-Linear-Regression/Salary_Data.csv) and obtained following graphs for training and test prediction.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Simple-Linear-Regression/SalaryvsExperienceTraining.png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Simple-Linear-Regression/SalaryvsExperienceTest.png" width="400" />
</div>

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%202.jpg">
</p>

### Day 3 :- Multiple Linear Regression
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/a2fc8b097e0705e7ee2537d54722ca71040801d6).
**Today's work**:- I have applied Multiple Linear Regression on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Multiple-Linear-Regression/50_Startups.csv) and also applied Backward Elimintion method to get the best model.

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%203.jpg?raw=true">
</p>

### Day 4 :- Polynomial Regression
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/89329b184190fe5648aff367c6c88509a1554605).
**Today's work**:- I have applied Polynomial Regression on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Polynomial-Regression/Position_Salaries.csv) to predict weather a employee is telling truth or bluff about his salary and got the following graphs for Linear and Polynomial Regression.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Polynomial-Regression/Truth%20or%20Bluff(Linear%20Regression).png" width="416" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Polynomial-Regression/Truth%20or%20Bluff(Polynomial%20Regression).png" width="400" />
</div>

### Day 5 :- Support Vector Regression(SVR)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/347de1dffef96e3a4116dcebe3d5d7000d63ba29).
**Today's work**:- I have applied Support Vector Regression(SVR) on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Polynomial-Regression/Position_Salaries.csv) to predict weather a employee is telling truth or bluff about his salary and got the following graphs for Linear and Polynomial Regression.

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Support-Vector-Regression(SVR)/Truth%20or%20Bluff(SVR).png">
</p>

### Day 6 :- Decision Tree Regression
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/89756f61dac0659300aabc3f2ab856b55d1ba37e).
**Today's work**:- I have applied Decision Regression on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Decision-Tree-Regression/Position_Salaries.csv) to predict weather a employee is telling truth or bluff about his salary and got the following graph for Decision Tree Regression and and also ploted the Tree.

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Decision-Tree-Regression/Truth%20or%20Bluff(Decision%20Tree%20Reqression).png"/>
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Decision-Tree-Regression/Truth%20or%20Bluff(Decision%20Tree).png" width="568" />
</p>
  
### Day 7 :- Random Forest Regression
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/775034a66985b63581eb21930e433d04ac295bfa).
**Today's work**:- I have applied Random Forest Regression on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Random-Forest-Regression/Position_Salaries.csv) to predict weather a employee is telling truth or bluff about his salary and got the following graphs for Decision Tree 10, 100 and 500 Decision Trees.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Random-Forest-Regression/Truth%20of%20Bluff(Random%20Forest%20Regresstion)%2010.png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Random-Forest-Regression/Truth%20of%20Bluff(Random%20Forest%20Regresstion)%20100.png" width="400" />
</div>

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Random-Forest-Regression/Truth%20of%20Bluff(Random%20Forest%20Regresstion)%20500.png"/>
</p>

### Day 8 :- R square and Estimated R square
**Today's work**:- I have learnt about the R square and Estimated R square and also find it on the the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Regression/Random-Forest-Regression/Position_Salaries.csv) by various studied Algorithms till now. Also studied about the pros and cons of various algorithms studied till now.

### Day 9 :- Logistic Regression
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/739beb74a029a693f2e110f2951ed2a182f743bd)
**Today's work**:- I have applied Logistic Regression on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Logistic_Regression/Social_Network_Ads.csv) to predict weather a person buy's a SUV car for a company and obtained the following graphs for training and test data sets.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Logistic_Regression/Logistic%20Regression%20(Training%20Set).png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Logistic_Regression/Logistic%20Regression%20(Test%20Set).png" width="400" />
</div>

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%204.jpg"/>
</p>

### Day 10 :- K Nearest Neighbours(K-NN)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/ec8b6346d7cd26a0409e7f621fe57208bef7f008)
**Today's work**:- I have applied K-NN Classifier on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/K-Nearest_Neighbors(K-NN)/Social_Network_Ads.csv) to predict weather a person buy's a SUV car for a company and obtained the following graphs for training and test data sets.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/K-Nearest_Neighbors(K-NN)/K-NN(Training%20Set).png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/K-Nearest_Neighbors(K-NN)/K-NN(Training%20Set).png" width="400" />
</div>

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%207.jpg"/>
</p>

### Day 11 :- Support Vector Machine(SVM)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/3e1ec9640135d5170ed5a76729bac68109e57eb0)
**Today's work**:- I have applied Linear Support Vector Machine(SVM) on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Support_Vector_Machine(SVM)/Social_Network_Ads.csv) to predict weather a person buy's a SUV car for a company and obtained the following graphs for training and test data sets.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Support_Vector_Machine(SVM)/SVM(Training%20Set).png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Support_Vector_Machine(SVM)/SVM(Test%20Set).png" width="400" />
</div>

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%2012.jpg"/>
</p>

### Day 12 :- Kernal Support Vector Machine(K-SVM)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/fd713e75a450d9dcd534f15bb48ac10c182e629d)
**Today's work**:- I have applied Kernal Support Vector Machine(K-SVM) on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Support_Vector_Machine(SVM)/Social_Network_Ads.csv) to predict weather a person buy's a SUV car for a company and obtained the following graphs for training and test data sets.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Kernel_SVM/Kernal%20SVM(Training%20Set).png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Kernel_SVM/Kernal%20SVM(Test%20Set).png" width="400" />
</div>

### Day 13 :- Naive Bayes
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/294409a6d3f8460b5d0920f36f44f9a627637a41)
**Today's work**:- Today I have learnt about the Bayes Theoram and its application. Then, I have applied Naive-Bayes algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Naive_Bayes/Social_Network_Ads.csv) to predict weather a person buy's a SUV car for a company and obtained the following graphs for training and test data sets.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Naive_Bayes/Naive-bayes(Training%20Set).png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Naive_Bayes/Naive-Bayes(Test%20Set).png" width="400" />
</div>

### Day 14 :- Decision Tree Classification
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/0df34c5e0c817c1ad06f88ce4edc5dcba3c5e95d)
**Today's work**:- I have applied Decision Tree Classification on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Decision_Tree_Classification/Social_Network_Ads.csv) to predict weather a person buy's a SUV car for a company and obtained the following graphs for training and test data sets and I also visulaized it by ploting an actuall tree.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Decision_Tree_Classification/DTC%20(Training%20Set).png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Decision_Tree_Classification/DTC%20(Test%20Set).png" width="400" />
</div>

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Decision_Tree_Classification/DTC%20Visualised.png"/>
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%2023.jpg"/>
</p>

### Day 15 :- Random Forest Classification
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/be57000803081c7a60beb6af9275f51d3c917e3a)
**Today's work**:- I have applied Random Forest Classification on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Random_Forest_Classification/Social_Network_Ads.csv) to predict weather a person buy's a SUV car for a company and obtained the following graphs for training and test data sets. Then I compared the results with changing the values of number of trees and obtained the following graph.

<div float="left">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Random_Forest_Classification/RFC%20(Training%20Set).png" width="400" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Random_Forest_Classification/RFC%20(Test%20Set).png" width="400" />
</div>

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Classification/Random_Forest_Classification/Classifier%20performance%20with%20Number%20of%20trees.png" />
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%2033.jpg"/>
</p>

### Day 16 :- Cumuative Accuracy Paradox Curve(CAP Curve)
**Today's work**:- Today, I studied about the Accuraccy Paradox of the Confusion Matrix and also analyse it using CAP Curve analysis method for getting the best possible model in various classification algorithms. I also find various pros and cons of various classification algorithms.

### Day 17 :- K-Means Clustering
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/e4481972ec0ce164c41eeb2a789f9e2668bb2677)
**Today's work**:- I have applied K-Means Clustering algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/K-Means_Clustering/Mall_Customers.csv) to predict spending score of person based on their anual income in a mall by making clusters. I first aplied the Elbow Method to obtain the threshhold value of K as shown in following graph in python and R, then plotted the curve based on value of k obtained and plotted the following graphs in Python and R.

| Python  | R |
| :--: | :--: |
|  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/K-Means_Clustering/The%20Elbow%20Method(K-MeansClusturing).png" width="400"/> |  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/K-Means_Clustering/The%20Elbow%20Method(R).png" width="400"/>  |
|  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/K-Means_Clustering/Clustor%20of%20Clients.png" width="400"/> |  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/K-Means_Clustering/Cluster%20of%20Customer.png" width="400"/>  |

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%2043.jpg"/>
</p>

### Day 18 :- Hierarchical-Clustering
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/e29b2be7943c3554294424683aff606ade83c1c2)
**Today's work**:- I have applied Hierarchical-Clustering algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/Hierarchical-Clustering/Mall_Customers.csv) to predict spending score of person based on their anual income in a mall by making clusters. I first find out the Dendogram of the dataset to obtain the threshhold value of K as shown in following Dendogram in python and R, then plotted the curve based on value of k obtained and plotted the following graphs in Python and R.

| Python  | R |
| :--: | :--: |
|  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/Hierarchical-Clustering/HC(Python).png" width="400"/> |  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/Hierarchical-Clustering/HC(R).png" width="400"/>  |

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Clustering/Hierarchical-Clustering/Dendrogram.png"/>
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Redme-images/Day%2054.jpg"/>
</p>

### Day 19 :- Apiori Association Rule Learning Algorithm
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/8fcdcba2ad6011572538ad565d709c952fffbeb9)
**Today's work**:- I have applied Apiori Association Rule Learning algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Association-Rule-Learning/Apriori/Market_Basket_Optimisation.csv) to pridict the optimized placement of objects in a supermarket for maximizing the revenue.

### Day 20 :- Eclat Association Rule Learning Algorithm
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/78328448b5d7a0fd556e163d2f3717c46cdd28c7)
**Today's work**:- I have applied Eclat Association Rule Learning algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Association-Rule-Learning/Eclat/Market_Basket_Optimisation.csv) to pridict the optimized placement of objects in a supermarket for maximizing the sale.

### Day 21 :- Upper Confidence Bound (UCB)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/2c0df4850c33303c778efdb634cf9c336919fb47)
**Today's work**:- I have applied Upper Confidence Bound (UCB) Reinforcement Learning Algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Reinforcement-Learning/Upper-Confidence-Bound(UCB)/Ads_CTR_Optimisation.csv) to pridict the best Ad for a car company based on their performance in different social media. It was done by giving 1 reward for if the user interacted with the Ad and 0 if he does't. I obtained the following Histogram based on the prediction.

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Reinforcement-Learning/Upper-Confidence-Bound(UCB)/Ads%20Histogram.png"/>
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Reinforcement-Learning/Upper-Confidence-Bound(UCB)/UCB_Algorithm_Slide.png"/>
</p>

### Day 22 :- Thompson Sampling
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/21cb8ca49de842a2505ae06acf9dc676ec22c20d)
**Today's work**:- I have applied Thompson Sampling Reinforcement Learning Algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Reinforcement-Learning/Thompson-Sampling/Ads_CTR_Optimisation.csv) to pridict the best Ad for a car company based on their performance in different social media. It was done by giving 1 reward for if the user interacted with the Ad and 0 if he does't. I obtained the following Histogram based on the prediction.

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Reinforcement-Learning/Thompson-Sampling/Ads%20Histogram.png"/>
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Reinforcement-Learning/Thompson-Sampling/Thompson_Sampling_Slide.png"/>
</p>

### Day 23 :- Natural Language Processing
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/feac237817741b08fbf7e775abf2c857d5470671)
**Today's work**:- I have processed the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Natural-Language-Processing/Restaurant_Reviews.tsv) for getting the best sparse matrix for pridicting weather the customer likes the food in a restaurant based on their reviews. I first removed the unnecessory words using NLP then obtained a sparse matrix of maximum 1500 features. I then, applied the Naive Bayes Classification algorithm and Random Forest Classification algorithm to pridict weather the customer likes the food or not.

### Day 24 :- Principal Component Analysis (PCA)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/a81c9cd007cf96dfc354f4851325572b72742034)
**Today's work**:- I have processed the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Dimensionality-Reduction/Principal_Component_Analysis(PCA)/Wine.csv) which has 12 features to reduce it to lesser no of fetures based on Principal Component Analysis Method which works on varience of feture. Then, I applied Support Vector Machine algorithm to pridict the customer segment based on their wine selection.

### Day 25 :- Linear Discriminant Analysis (LDA)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/915391fad887f3fba133d5030545bc415f70aa82)
**Today's work**:- I have processed the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Dimensionality-Reduction/Linear_Discriminant_Analysis(LDA)/Wine.csv) which has 12 features to reduce it to lesser no of fetures based on Linear Discriminant Analysis Method. Then, I applied Support Vector Machine algorithm to pridict the customer segment based on their wine selection.

### Day 26 :- Kernal PCA
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/ce1a923da91dc9b547ef09878f829ceb4413efb8)
**Today's work**:- I have processed the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Dimensionality-Reduction/Kernel_PCA/Social_Network_Ads.csv) to reduce the dataset to lesser no of fetures based on Kernal PCA of Gaussian Kernal. Then, I applied Logistic Regression to pridict the weather a person buy's a SUV car for a company.

### Day 27 :- K-Fold Cross Validations
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/8fa5fac9777818f5d0cf6941c15314f4f3e3fd46)
**Today's work**:- I have Applied K-Fold Cross Validations Technique on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Model-Selection-%26-Boosting/Model-Selection/Social_Network_Ads.csv) for dividing the dataset into 10 parts to get the best model and got an average accuraccy of 91 percent.

### Day 28 :- Grid Search
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/cd46a10b0c494cd05f816ee678335dce2427f540)
**Today's work**:- I have Applied Grid Search Algorithm on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Model-Selection-%26-Boosting/Model-Selection/Social_Network_Ads.csv) for getting the best model. I first applied linear kernal with penalities 1, 10, 100, 1000 then applied rbf kernal with penalities 1, 10, 100, 1000 and got an average accuraccy of 90 percent.

### Day 29 :- XGBoost
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/70b8650109a62d26fad7f5565b776b638bc5bea8)
**Today's work**:- I have applied XGBoost on the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Model-Selection-%26-Boosting/XGBoost/Churn_Modelling.csv) for obtaining the best model and got an accuracy of 87 percent.

## Deep Learning
### Day 30 :- Artificial Neural Networks
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/4fcb2603db72c6c027a37a9b7c441897785f06a7)
**Today's work**:- I have created Artificial Neural Network for the following [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Deep-Learning/Artificial-Neural-Networks(ANN)/Churn_Modelling.csv) for predicting weather the customer of the bank exited or not by creating a Artificial Neural Network of one input layer having 6 nodes, one hidden layer of 6 nodes and one output layer having 1 nodes. I further obtained an accuracy of 86 precent by obtaining a confusion matrix.

### Day 31 :- Convolutional Neural Networks(CNN)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/930b281bfc8948f5bdaf7e0c2ea15815cc94bce1)
**Today's work**:- I have created Convolutional Neural Network for predicting weather the image is of cat or dog using 5000 images of both(4000 training and 1000 test) and got an Accuracy of 85 percent. I first applied the convolution operation with ReLU as activation function on each image then, applied pooling step and then flatterened the result and fed it into the Neural Network and obtained the above prediction successfully.

### Day 31 :- Recurrent Neural Networks(CNN)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/4cf45f44910502ee2534cff80db01a56797cc5ff)
**Today's work**:- I have created Recurrent Neural Network for predicting weather the google stock price of 2017 using previous 3 months data to pridict next day's stock price. I first applied Sequential Kreas model with 50 inputs neurons then 3 hidden layers of 50 neurons each and finally one output layer of one neuron , finally obtained the following graph.

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Deep-Learning/Recurrent_Neural_Networks(RNN)/stock%20prediction.png"/>
</p>

### Day 32 :- Self Organizing Maps (SOM)
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/e7b6013113d267beee1e9d5143f06bdeb276796e)
**Today's work**:- I have created Self Organizing Maps (SOM) on [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Deep-Learning/Self-Organizing-Maps%20(SOM)/Credit_Card_Applications.csv) for predicting weather the user is fraud or not when he applies for a cridit card application. I have used a third party library [minisom](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Deep-Learning/Self-Organizing-Maps%20(SOM)/minisom.py) to obtain the following Self Organizing Map.

<p align="center">
  <img src="https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Deep-Learning/Self-Organizing-Maps%20(SOM)/img.png"/>
</p>

### Day 33 :- Going from Supervised to Unsupervised Learning
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/1c2e7bc6b2d0efbb2259803110fdfc4389a5dd00)
**Today's work**:- Yesterday, I have created Supervised Self Organizing Maps (SOM) on [dataset](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Deep-Learning/Self-Organizing-Maps%20(SOM)/Credit_Card_Applications.csv) for predicting weather the user is fraud or not when he applies for a cridit card application. I have used a third party library [minisom](https://github.com/Shritesh99/100DaysofMLCodeChallenge/blob/master/Deep-Learning/Self-Organizing-Maps%20(SOM)/minisom.py) to obtain the Self Organizing Map. Today, I have made changes to existing one and takeing it from Supervised to UnSupervised Learning by creating a Sequential Kreas Neural Network with adam optimizer.

### Day 34 :- Boltzmann Machine
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/26f9518d61312d8e9d6b03b6d488576ba3f48c5a)
**Today's work**:- I have created UnSupervised movie recommendation system for recommending a movie to a new user using Deep Boltzmann Machine.

### Day 35 :- AutoEncoders
#### Check out the code from [here](https://github.com/Shritesh99/100DaysofMLCodeChallenge/commit/7a1907e63ca6591483bb43e34b0cec50951f0f60)
**Today's work**:- I have created UnSupervised movie recommendation system for recommending a movie to a new user using AutoEncoders.

## Project :- Chatbot

## Day 36 to 40 :- 
#### Check out the code from [here](https://github.com/Shritesh99/Chatbot/blob/master/Chatbot.ipynb)
Worked on a chatbot project based on Sequence to Sequence (seq2seq) Deep Natural Language Processing model in which I have used Cornell Movie-Dialogs Dataset which consist of 220,579 conversational exchanges between 10,292 pairs of movie characters which involves 9,035 characters from 617 movies.
